
# Compiler stages (in depth)

The compiler is divided into several stages, each of which is responsible for a different part of the compilation process. The stages are as follows:

## 1. Application and CLI parsing

The first stage of the compiler is the parsing of the command line arguments and the application configuration file. The compiler uses the `llvm::cl` library to parse the command line arguments.

The application is in charge of initializing the CLI parser and executing the main function of the compiler. 

The CLI parser is responsible for parsing the command line arguments and setting the appropriate flags in the compiler.

## 2. Package manager

The package manager is responsible for downloading and installing the dependencies of the application. The package manager is implemented as a separate library that is linked to the compiler.

It's responsible for the following tasks:
* Creating a package dependency graph
* Downloading and installing packages
* Resolving package dependencies
* Export used packages into snowball's internal package format
  * Stored inside `.sn/deps/modules.dep`
* Caching downloaded packages

## 3. Compiler initialization

The compiler initialization stage is responsible for setting up the compiler environment. This includes:
* Fetching all needed packages for the compilation process (see package manager)
* Execute the compiler's main function

## 4. Frontend

Each compiler stage is responsible for a different part of the compilation process. The frontend is responsible for parsing the source code and generating AST (Abstract Syntax Tree) models.

The frontend is divided into several sub-stages:

### 4.1. Lexer

The lexer is responsible for tokenizing the source code. It reads the source code character by character and generates a stream of tokens. 

A token is a small unit of the source code that represents a single element, such as a keyword, identifier, or literal.

Note that the frontend processes can be multithreaded, as every file can be processed independently. It can also be cached to speed up the compilation process.

For example, the following source code will be tokenized into the following tokens:

```c
"hello" + world 

-> [Token("hello"), Token(+), Token("world")]
```

### 4.2. Parser

The parser is responsible for parsing the stream of tokens generated by the lexer and generating an Abstract Syntax Tree (AST). The AST is a tree-like data structure that represents the structure of the source code.

The parser uses a grammar to define the syntax of the language. An AST node represents a single element of the source code, such as a function declaration, variable declaration, or expression.  

For example, the following source code will be parsed into the following AST:

```swift
func hello() i32 {
  return 2;
}
```

AST:

```rs
FunctionDeclarationNode
  name: "hello"
  returnType: i32
  body:
    ReturnStatementNode
      value: IntegerLiteralNode
        value: 2
```

## 5. Middle-end

The middle-end is responsible for transforming the AST generated by the frontend into an intermediate representation (IR). The IR is a low-level representation of the source code that is closer to the target machine.

It performs several optimizations on the IR and type checking. The middle-end is divided into several sub-stages:

### 5.1. Type checking

The type checking stage is responsible for verifying that the types of expressions and statements are correct. It ensures that the source code is semantically correct.

It's also responsible for instantiating generic types and resolving type inference.

### 5.2. IR generation

The IR generation stage is responsible for transforming the typed AST into an intermediate representation (IR). The IR is a low-level representation of the source code that is closer to the target machine.

The IR is a tree-like data structure that represents the operations and data flow of the source code. It's usually represented as a sequence of instructions.

### 5.3. Optimization passes

The optimization passes stage is responsible for applying various optimizations to the IR. These optimizations improve the performance of the generated code by reducing the number of instructions and improving the data flow.

For example, devirtualization, constant folding, and inlining are common optimization passes.

### 5.4. Static code execution

The static code execution stage is responsible for executing parts of the code at compile time. This can be used to evaluate constant expressions, perform compile-time checks, and overall make use of a small subset of the language at compile time.

This will only be done if the compiler detects any static calls or expressions that can be evaluated at compile time.

```swift
#[compile_time]
func hello() {
  return 2 + 2;
}

func main() {
  let x = static hello();
}
```

## 6. Backend

The backend is responsible for generating the target machine code from the IR. The backend can have multiple sub-stages depending on the desired output format.

These backends can be:
* LLVM IR
* assembly code
* shared object files
* executable files
* static libraries
* JavaScript code (WebAssembly)
* and more...

Note that most of these backends use the `lld` driver to link the generated object files into the final output.
